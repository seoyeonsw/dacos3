#ë¦¬ë·° ìš”ì•½ ë¯¸ê²°í•© ìƒíƒœ
import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv('cleaned_amazon_0519.csv')
    df = df.dropna(subset=['about_product', 'discounted_price', 'discount_percentage'])
    return df

df = load_data()

st.title("ğŸ§­ ì˜ˆë¹„ íŒë§¤ìë¥¼ ìœ„í•œ ì‹œì¥ ë‚´ ìœ ì‚¬ ìƒí’ˆ íƒìƒ‰ê¸°")

# ğŸ” ì¹´í…Œê³ ë¦¬ ìë™ì™„ì„±
category_list = sorted(df['category'].dropna().unique().tolist())
typed = st.text_input("ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰", "")
filtered_categories = [cat for cat in category_list if typed.lower() in cat.lower()]
selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", filtered_categories) if filtered_categories else None

# ğŸ’¬ ì œí’ˆ ì„¤ëª… ì…ë ¥ + ê°€ê²©/í• ì¸ìœ¨
product_desc = st.text_area("ìƒí’ˆ ì„¤ëª… ì…ë ¥", placeholder="ì˜ˆì‹œ: Outdoor camping gear with solar panel")
actual_price = st.number_input("ì •ê°€ (â‚¹)", min_value=0, value=3000)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)

# ğŸ’¸ ìë™ ê³„ì‚°ëœ í• ì¸ê°€ í‘œì‹œ
discounted_price = int(actual_price * (1 - discount_pct / 100))
st.markdown(f"**í• ì¸ê°€ (ìë™ ê³„ì‚°): â‚¹{discounted_price}**")

# â–¶ï¸ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("ì‹œì¥ ë‚´ ìœ ì‚¬ ìƒí’ˆ íƒìƒ‰í•˜ê¸°"):
    if selected_category is None:
        st.warning("ì¹´í…Œê³ ë¦¬ë¥¼ ë¨¼ì € ê²€ìƒ‰ í›„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        df_filtered = df[df['category'] == selected_category]

        if len(df_filtered) < 5:
            st.error("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ ë‚´ ì œí’ˆ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        else:
            tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
            tfidf_matrix = tfidf.fit_transform(df_filtered['about_product'])
            query_vec = tfidf.transform([product_desc])
            cos_sim = cosine_similarity(query_vec, tfidf_matrix)

            top_n = min(50, len(df_filtered))
            top_indices = cos_sim[0].argsort()[::-1][:top_n]
            candidate_df = df_filtered.iloc[top_indices].copy()

            if len(candidate_df) < 3:
                st.error("ìœ ì‚¬í•œ ì œí’ˆì´ 3ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ì„¤ëª…ì„ ë‹¤ì‹œ ì…ë ¥í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                # ğŸ¯ ìœ ì‚¬ë„ ì§„ë‹¨
                mean_sim = cos_sim[0][top_indices].mean()
                max_sim = cos_sim[0][top_indices].max()

                similarity_warnings = []
                if mean_sim < 0.05:
                    similarity_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ì´ ë‹¤ë¥¸ ì œí’ˆë“¤ê³¼ ì „ë°˜ì ìœ¼ë¡œ í¬ê²Œ ë‹¤ë¦…ë‹ˆë‹¤. ìœ ì‚¬ ì œí’ˆ ëª©ë¡ì˜ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í‰ê·  ìœ ì‚¬ë„ ë‚®ìŒ)\nê¶Œì¥: ì„¤ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ë³´ì„¸ìš”.")
                if max_sim < 0.1:
                    similarity_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ê³¼ ë§¤ìš° ìœ ì‚¬í•œ ì œí’ˆì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ìœ ì‚¬ ì œí’ˆ ëª©ë¡ì˜ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ìµœê³  ìœ ì‚¬ë„ ë‚®ìŒ)")

                # âœ… í´ëŸ¬ìŠ¤í„°ë§
                num_cols = ['actual_price', 'discount_percentage']
                candidate_df['actual_price'] = candidate_df['discounted_price'] / (1 - candidate_df['discount_percentage'] / 100)
                X = candidate_df[['actual_price', 'discount_percentage']]
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                k = min(5, len(candidate_df))
                kmeans = KMeans(n_clusters=k, random_state=0)
                candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

                input_features = [[actual_price, discount_pct]]
                input_scaled = scaler.transform(input_features)
                input_cluster = kmeans.predict(input_scaled)[0]

                cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
                member_scaled = scaler.transform(cluster_members[['actual_price', 'discount_percentage']])
                dists = euclidean_distances(input_scaled, member_scaled)[0]
                cluster_members = cluster_members.copy()
                cluster_members['distance'] = dists

                top_matches = cluster_members.sort_values('distance').head(3).reset_index(drop=True)

                # âš ï¸ ê²½ê³  ë¨¼ì € ì¶œë ¥
                if similarity_warnings:
                    st.warning("\n\n".join(similarity_warnings))

                # âœ… ì¹´ë“œ í˜•íƒœ ê²°ê³¼ ì¶œë ¥
                st.subheader("ğŸ“‹ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")

                for i, row in top_matches.iterrows():
                    st.markdown(f"### {i+1}ìœ„. {row['product_name']}")
                    cols = st.columns([1, 3])
                    with cols[0]:
                        st.image(row['img_link'], width=120)
                    with cols[1]:
                        st.markdown(f"**Distance**: `{row['distance']:.4f}`")
                        st.markdown(f"`ì •ê°€`: â‚¹{int(row['actual_price'])} / `í• ì¸ìœ¨`: {int(row['discount_percentage'])}% / `í• ì¸ê°€`: â‚¹{int(row['discounted_price'])}")
                        st.markdown(f"`í‰ì `: {row.get('rating', 'N/A')} â­ / `ë¦¬ë·° ìˆ˜`: {row.get('rating_count', 'N/A')}")
