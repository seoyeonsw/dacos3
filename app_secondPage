# ğŸ“¦ ì˜ˆë¹„ ìƒí’ˆ íŒë§¤ììš© Streamlit ì•±
import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from transformers import T5Tokenizer, T5ForConditionalGeneration

# ğŸ“‚ ë°ì´í„° ë¡œë”© ë° ì •ê°€ ê³„ì‚°
def load_data():
    df = pd.read_csv("cleaned_amazon_0519.csv")
    df = df.dropna(subset=['about_product', 'discounted_price', 'discount_percentage'])
    df['actual_price'] = df['discounted_price'] / (1 - df['discount_percentage'] / 100)
    df[['cat1', 'cat2', 'cat3']] = df['category'].str.split('|', expand=True, n=2)
    return df

@st.cache_data
def load_tokenizer_model():
    tokenizer = T5Tokenizer.from_pretrained("t5-base")
    model = T5ForConditionalGeneration.from_pretrained("t5-base")
    return tokenizer, model

def t5_summarize(text, max_length=50):
    input_text = "summarize: " + text.strip().replace("\n", " ")
    inputs = tokenizer.encode(input_text, return_tensors="pt", truncation=True)
    outputs = model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# âœ… ë°ì´í„° ì¤€ë¹„
st.title("ğŸ§­ ì˜ˆë¹„ íŒë§¤ìë¥¼ ìœ„í•œ ì‹œì¥ ìœ ì‚¬ ì œí’ˆ íƒìƒ‰ê¸°")
st.markdown("ì•± ì²« êµ¬ë™ ì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ë¡œë“œë¡œ ì¸í•´ ë¡œë”©ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
df = load_data()
tokenizer, model = load_tokenizer_model()

# ğŸ” ì¹´í…Œê³ ë¦¬ ë“œë¦´ë‹¤ìš´ ì„ íƒ
cat1 = st.selectbox("1ì°¨ ì¹´í…Œê³ ë¦¬", sorted(df['cat1'].dropna().unique()))
cat2_options = df[df['cat1'] == cat1]['cat2'].dropna().unique()
cat2 = st.selectbox("2ì°¨ ì¹´í…Œê³ ë¦¬", sorted(cat2_options))
cat3_options = df[(df['cat1'] == cat1) & (df['cat2'] == cat2)]['cat3'].dropna().unique()
cat3 = st.selectbox("3ì°¨ ì¹´í…Œê³ ë¦¬", ["ì „ì²´"] + sorted(cat3_options))

# âœ… ìµœì¢… ì¹´í…Œê³ ë¦¬ í•„í„°ë§
if cat3 == "ì „ì²´":
    df_filtered = df[(df['cat1'] == cat1) & (df['cat2'] == cat2)]
else:
    df_filtered = df[(df['cat1'] == cat1) & (df['cat2'] == cat2) & (df['cat3'] == cat3)]

# ğŸ“ ì‚¬ìš©ì ì…ë ¥
product_desc = st.text_area("ì œí’ˆ ì„¤ëª… ì…ë ¥", placeholder="ì˜ˆì‹œ: Outdoor camping gear with solar panel")
actual_price = st.number_input("ì •ê°€ (â‚¹)", min_value=0, value=3000)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)
discounted_price = int(actual_price * (1 - discount_pct / 100))
st.markdown(f"**í• ì¸ê°€ (ìë™ ê³„ì‚°): â‚¹{discounted_price}**")

# â–¶ï¸ ì‹¤í–‰ ë²„íŠ¼
if st.button("ìœ ì‚¬ ì œí’ˆ íƒìƒ‰í•˜ê¸°"):
    if len(df_filtered) < 5:
        st.error("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ ë‚´ ì œí’ˆ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")
    else:
        # ğŸ” TF-IDF + ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
        tfidf_matrix = tfidf.fit_transform(df_filtered['about_product'])
        query_vec = tfidf.transform([product_desc])
        cos_sim = cosine_similarity(query_vec, tfidf_matrix)

        top_indices = cos_sim[0].argsort()[::-1][:50]
        candidate_df = df_filtered.iloc[top_indices].copy()

        # ğŸ¯ ìœ ì‚¬ë„ ì§„ë‹¨
        mean_sim = cos_sim[0][top_indices].mean()
        max_sim = cos_sim[0][top_indices].max()
        sim_warnings = []
        if mean_sim < 0.05:
            sim_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ì´ ë‹¤ë¥¸ ì œí’ˆë“¤ê³¼ ì „ë°˜ì ìœ¼ë¡œ í¬ê²Œ ë‹¤ë¦…ë‹ˆë‹¤. (í‰ê·  ìœ ì‚¬ë„ ë‚®ìŒ)")
        if max_sim < 0.1:
            sim_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ê³¼ ë§¤ìš° ìœ ì‚¬í•œ ì œí’ˆì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. (ìµœê³  ìœ ì‚¬ë„ ë‚®ìŒ)")

        # ğŸ“Š KMeans í´ëŸ¬ìŠ¤í„°ë§ (k=4)
        num_cols = ['actual_price', 'discount_percentage']
        X = candidate_df[num_cols]
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        kmeans = KMeans(n_clusters=4, random_state=0)
        candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

        input_scaled = scaler.transform([[actual_price, discount_pct]])
        input_cluster = kmeans.predict(input_scaled)[0]

        cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
        member_scaled = scaler.transform(cluster_members[num_cols])
        dists = euclidean_distances(input_scaled, member_scaled)[0]
        cluster_members = cluster_members.copy()
        cluster_members['distance'] = dists
        top_matches = cluster_members.sort_values('distance').head(3).reset_index(drop=True)

        # âš ï¸ ìœ ì‚¬ë„ ê²½ê³  ì¶œë ¥
        if sim_warnings:
            st.warning("\n\n".join(sim_warnings))

        # ğŸ“‹ ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ“‹ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")
        for i, row in top_matches.iterrows():
            st.markdown(f"### {i+1}ìœ„. {row['product_name']}")
            cols = st.columns([1, 3])
            with cols[0]:
                st.image(row['img_link'], width=120)
            with cols[1]:
                st.markdown(f"**Distance**: `{row['distance']:.4f}`")
                st.markdown(f"`ì •ê°€`: â‚¹{int(row['actual_price'])} / `í• ì¸ìœ¨`: {int(row['discount_percentage'])}% / `í• ì¸ê°€`: â‚¹{int(row['discounted_price'])}")
                st.markdown(f"`í‰ì `: {row.get('rating', 'N/A')} â­ / `ë¦¬ë·° ìˆ˜`: {row.get('rating_count', 'N/A')}")
                # ê°œë³„ ë¦¬ë·° ìš”ì•½
                summary_text = row.get("full_summary", "")
                if pd.notna(summary_text) and summary_text.strip():
                    with st.spinner("AIê°€ í•´ë‹¹ ì œí’ˆ ë¦¬ë·° ìš”ì•½ ì¤‘..."):
                        summary = t5_summarize(summary_text, max_length=50)
                        st.markdown(f"ğŸ§  **AI ë¦¬ë·° ìš”ì•½:** {summary}")
                else:
                    st.markdown("ğŸ§  **AI ë¦¬ë·° ìš”ì•½:** (ë¦¬ë·° ìš”ì•½ ì—†ìŒ)")

        # ì „ì²´ ë¦¬ë·° ìš”ì•½
        all_text = " ".join(top_matches['full_summary'].dropna().astype(str).tolist())
        if all_text.strip():
            with st.spinner("AIê°€ ìƒìœ„ ì œí’ˆë“¤ì˜ ë¦¬ë·° ì „ì²´ ìš”ì•½ ì¤‘..."):
                full_summary = t5_summarize(all_text, max_length=100)
                st.subheader("ğŸ§  ìƒìœ„ ì œí’ˆ ë¦¬ë·° ì „ì²´ ìš”ì•½")
                st.markdown(f"> {full_summary}")
